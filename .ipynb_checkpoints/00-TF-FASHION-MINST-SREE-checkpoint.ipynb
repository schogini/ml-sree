{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6770eb14",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"></ul></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "63c225de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.19.5'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.__version__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c870ce7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.7.0'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "143d66e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "b5eb36d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist = tf.keras.datasets.fashion_mnist\n",
    "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "81bbe9e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x167fc5940>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# first_image = mnist.train.images[0]\n",
    "first_image = training_images[0]\n",
    "first_image = np.array(first_image, dtype='uint8')\n",
    "pixels = first_image.reshape((28, 28))\n",
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(pixels, cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "21ac6fc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import PIL.Image as pil\n",
    "# first_image = training_images[0].reshape(28,28)\n",
    "# img = pil.fromarray(np.uint8(first_image * 255) , 'L')\n",
    "# img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "72dc00f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_images  = training_images / 255.0\n",
    "test_images = test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e074ebfd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ea44a082",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(), \n",
    "                                    tf.keras.layers.Dense(\n",
    "                                            128, activation=tf.nn.relu), \n",
    "                                    tf.keras.layers.Dense(\n",
    "                                            10, activation=tf.nn.softmax)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584fb8d0",
   "metadata": {},
   "source": [
    "**Sequential**: That defines a SEQUENCE of layers in the neural network\n",
    "  \n",
    "**Flatten**: Remember earlier where our images were a square when\n",
    "you printed them out? Flatten just takes that square and turns it\n",
    "into a 1-dimensional set.\n",
    "  \n",
    "**Dense**: Adds a layer of neurons\n",
    "  \n",
    "Each layer of neurons needs an **activation function** to tell them what to\n",
    "do. There are lots of options, but just use these for now. \n",
    "  \n",
    "**Relu** effectively means \"If X>0 return X, else return 0\" -- so what it does\n",
    " it only passes values 0 or greater to the next layer in the network.\n",
    "  \n",
    "**Softmax** takes a set of values, and effectively picks the biggest one, so,\n",
    " for example, if the output of the last layer looks like [0.1, 0.1, 0.05, 0.1,\n",
    " 9.5, 0.1, 0.05, 0.05, 0.05], it saves you from fishing through it looking for\n",
    " the biggest value, and turns it into [0,0,0,0,1,0,0,0,0] -- \n",
    " The goal is to save a lot of coding!\n",
    "  \n",
    "The next thing to do, now the model is defined, is to actually build it.\n",
    "You do this by compiling it with an optimizer and loss function as before -- \n",
    "and then you train it by calling **model.fit ** asking it to fit your training\n",
    "data to your training labels -- i.e. have it figure out the relationship between\n",
    "the training data and its actual labels, so in future, if you have data that\n",
    "looks like the training data, then it can make a prediction for what that data\n",
    "would look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "389a5fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
    "              loss = 'sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "886d1bbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1875/1875 [==============================] - 13s 6ms/step - loss: 0.4962 - accuracy: 0.8248\n",
      "Epoch 2/5\n",
      "1875/1875 [==============================] - 11s 6ms/step - loss: 0.3764 - accuracy: 0.8636\n",
      "Epoch 3/5\n",
      "1875/1875 [==============================] - 14s 7ms/step - loss: 0.3377 - accuracy: 0.8766\n",
      "Epoch 4/5\n",
      "1875/1875 [==============================] - 8s 5ms/step - loss: 0.3145 - accuracy: 0.8852\n",
      "Epoch 5/5\n",
      "1875/1875 [==============================] - 8s 4ms/step - loss: 0.2956 - accuracy: 0.8912\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14773e4f0>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(training_images, training_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a3005e2",
   "metadata": {},
   "source": [
    "Once it's done training -- you should see an accuracy value at the end of the\n",
    "final epoch. It might look something like 0.9098. This tells you that your\n",
    "neural network is about 91% accurate in classifying the training data. I.E.,\n",
    "it figured out a pattern match between the image and the labels that worked\n",
    "91% of the time. Not great, but not bad considering it was only trained for 5\n",
    "epochs and done quite quickly.\n",
    "  \n",
    "But how would it work with unseen data? That's why we have the test images. We \n",
    "can call model.evaluate, and pass in the two sets, and it will report back the\n",
    "loss for each. Let's give it a try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "94552033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "313/313 [==============================] - 1s 3ms/step - loss: 0.3607 - accuracy: 0.8705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.3607393801212311, 0.8705000281333923]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(test_images, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aecf9bc",
   "metadata": {},
   "source": [
    "For me, that returned an accuracy of about .8838, which means it was \n",
    "about 88% accurate. As expected it probably would not do as well with *unseen*\n",
    "data as it did with data it was trained on!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c88af41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " flatten_1 (Flatten)         (None, 784)               0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 128)               100480    \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 10)                1290      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 101,770\n",
      "Trainable params: 101,770\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4aa0bb8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]], dtype=float32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_img_as_input = test_images[0]\n",
    "example_img_as_input = (np.expand_dims(example_img_as_input,0))\n",
    "model.predict(example_img_as_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f1c2d329",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2d66afa3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example_img_as_input = test_images[1]\n",
    "example_img_as_input = (np.expand_dims(example_img_as_input,0))\n",
    "model.predict(example_img_as_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "612e31a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "736c1618",
   "metadata": {},
   "source": [
    "Labels\n",
    "Each training and test example is assigned to one of the following labels:\n",
    "```\n",
    "Label\tDescription\n",
    "0\tT-shirt/top\n",
    "1\tTrouser\n",
    "2\tPullover\n",
    "3\tDress\n",
    "4\tCoat\n",
    "5\tSandal\n",
    "6\tShirt\n",
    "7\tSneaker\n",
    "8\tBag\n",
    "9\tAnkle boot\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd57c8c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.01176471,\n",
       "        0.00392157, 0.        , 0.        , 0.02745098, 0.        ,\n",
       "        0.14509804, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00392157, 0.00784314,\n",
       "        0.        , 0.10588235, 0.32941176, 0.04313725, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.46666667, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.00392157, 0.        ,\n",
       "        0.        , 0.34509804, 0.56078431, 0.43137255, 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.08627451, 0.36470588,\n",
       "        0.41568627, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.01568627, 0.        ,\n",
       "        0.20784314, 0.50588235, 0.47058824, 0.57647059, 0.68627451,\n",
       "        0.61568627, 0.65098039, 0.52941176, 0.60392157, 0.65882353,\n",
       "        0.54901961, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.00784314, 0.        , 0.04313725,\n",
       "        0.5372549 , 0.50980392, 0.50196078, 0.62745098, 0.69019608,\n",
       "        0.62352941, 0.65490196, 0.69803922, 0.58431373, 0.59215686,\n",
       "        0.56470588, 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00392157, 0.        , 0.00784314, 0.00392157,\n",
       "        0.        , 0.01176471, 0.        , 0.        , 0.45098039,\n",
       "        0.44705882, 0.41568627, 0.5372549 , 0.65882353, 0.6       ,\n",
       "        0.61176471, 0.64705882, 0.65490196, 0.56078431, 0.61568627,\n",
       "        0.61960784, 0.04313725, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.00392157,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.01176471, 0.        , 0.        , 0.34901961, 0.54509804,\n",
       "        0.35294118, 0.36862745, 0.6       , 0.58431373, 0.51372549,\n",
       "        0.59215686, 0.6627451 , 0.6745098 , 0.56078431, 0.62352941,\n",
       "        0.6627451 , 0.18823529, 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.00784314, 0.01568627, 0.00392157, 0.        ,\n",
       "        0.        , 0.        , 0.38431373, 0.53333333, 0.43137255,\n",
       "        0.42745098, 0.43137255, 0.63529412, 0.52941176, 0.56470588,\n",
       "        0.58431373, 0.62352941, 0.65490196, 0.56470588, 0.61960784,\n",
       "        0.6627451 , 0.46666667, 0.        ],\n",
       "       [0.        , 0.        , 0.00784314, 0.00784314, 0.00392157,\n",
       "        0.00784314, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.10196078, 0.42352941, 0.45882353, 0.38823529, 0.43529412,\n",
       "        0.45882353, 0.53333333, 0.61176471, 0.5254902 , 0.60392157,\n",
       "        0.60392157, 0.61176471, 0.62745098, 0.55294118, 0.57647059,\n",
       "        0.61176471, 0.69803922, 0.        ],\n",
       "       [0.01176471, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.08235294, 0.20784314, 0.36078431,\n",
       "        0.45882353, 0.43529412, 0.40392157, 0.45098039, 0.50588235,\n",
       "        0.5254902 , 0.56078431, 0.60392157, 0.64705882, 0.66666667,\n",
       "        0.60392157, 0.59215686, 0.60392157, 0.56078431, 0.54117647,\n",
       "        0.58823529, 0.64705882, 0.16862745],\n",
       "       [0.        , 0.        , 0.09019608, 0.21176471, 0.25490196,\n",
       "        0.29803922, 0.33333333, 0.4627451 , 0.50196078, 0.48235294,\n",
       "        0.43529412, 0.44313725, 0.4627451 , 0.49803922, 0.49019608,\n",
       "        0.54509804, 0.52156863, 0.53333333, 0.62745098, 0.54901961,\n",
       "        0.60784314, 0.63137255, 0.56470588, 0.60784314, 0.6745098 ,\n",
       "        0.63137255, 0.74117647, 0.24313725],\n",
       "       [0.        , 0.26666667, 0.36862745, 0.35294118, 0.43529412,\n",
       "        0.44705882, 0.43529412, 0.44705882, 0.45098039, 0.49803922,\n",
       "        0.52941176, 0.53333333, 0.56078431, 0.49411765, 0.49803922,\n",
       "        0.59215686, 0.60392157, 0.56078431, 0.58039216, 0.49019608,\n",
       "        0.63529412, 0.63529412, 0.56470588, 0.54117647, 0.6       ,\n",
       "        0.63529412, 0.76862745, 0.22745098],\n",
       "       [0.2745098 , 0.6627451 , 0.50588235, 0.40784314, 0.38431373,\n",
       "        0.39215686, 0.36862745, 0.38039216, 0.38431373, 0.4       ,\n",
       "        0.42352941, 0.41568627, 0.46666667, 0.47058824, 0.50588235,\n",
       "        0.58431373, 0.61176471, 0.65490196, 0.74509804, 0.74509804,\n",
       "        0.76862745, 0.77647059, 0.77647059, 0.73333333, 0.77254902,\n",
       "        0.74117647, 0.72156863, 0.14117647],\n",
       "       [0.0627451 , 0.49411765, 0.67058824, 0.7372549 , 0.7372549 ,\n",
       "        0.72156863, 0.67058824, 0.6       , 0.52941176, 0.47058824,\n",
       "        0.49411765, 0.49803922, 0.57254902, 0.7254902 , 0.76470588,\n",
       "        0.81960784, 0.81568627, 1.        , 0.81960784, 0.69411765,\n",
       "        0.96078431, 0.98823529, 0.98431373, 0.98431373, 0.96862745,\n",
       "        0.8627451 , 0.80784314, 0.19215686],\n",
       "       [0.        , 0.        , 0.        , 0.04705882, 0.2627451 ,\n",
       "        0.41568627, 0.64313725, 0.7254902 , 0.78039216, 0.82352941,\n",
       "        0.82745098, 0.82352941, 0.81568627, 0.74509804, 0.58823529,\n",
       "        0.32156863, 0.03137255, 0.        , 0.        , 0.        ,\n",
       "        0.69803922, 0.81568627, 0.7372549 , 0.68627451, 0.63529412,\n",
       "        0.61960784, 0.59215686, 0.04313725],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ],\n",
       "       [0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        ]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdd6c22",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
