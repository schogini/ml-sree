
https://github.com/codebasics/py/blob/master/ML/7_logistic_reg/7_logistic_regression.ipynb


import pandas as pd
from matplotlib import pyplot as plt
%matplotlib inline

df = pd.read_csv("drive/MyDrive/Colab Notebooks/insurance_data.csv")
df.head()

age	bought_insurance
0	22	0
1	25	0
2	47	1
3	52	0
4	46	1

plt.scatter(df.age,df.bought_insurance,marker='+',color='red')



from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(df[['age']],df.bought_insurance,train_size=0.8)

X_test

age
16	25
21	26
1	25
17	58
2	47
24	50

from sklearn.linear_model import LogisticRegression
model = LogisticRegression()

model.fit(X_train, y_train)

# LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=100,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=None, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)

X_test

age
16	25
21	26
1	25
17	58
2	47
24	50

y_predicted = model.predict(X_test)

model.predict_proba(X_test)

array([[0.93630859, 0.06369141],
       [0.9264839 , 0.0735161 ],
       [0.93630859, 0.06369141],
       [0.08361538, 0.91638462],
       [0.33177366, 0.66822634],
       [0.23827077, 0.76172923]])

model.score(X_test,y_test)

0.8333333333333334

y_predicted

array([0, 0, 0, 1, 1, 1])

X_test

age
16	25
21	26
1	25
17	58
2	47
24	50


import math
def sigmoid(x):
  return 1 / (1 + math.exp(-x))

# model.coef_ indicates value of m in y=m*x + b equation
model.coef_
model.intercept_

def prediction_function(age):
    z = 0.042 * age - 1.53 # 0.04150133 ~ 0.042 and -1.52726963 ~ -1.53
    y = sigmoid(z)
    return y


age = 35
prediction_function(age)

0.4850044983805899

# 0.485 is less than 0.5 which means person with 35 age will not buy insurance

age = 43
prediction_function(age)

# is more than 0.5 which means person with 43 will buy the insuranc


